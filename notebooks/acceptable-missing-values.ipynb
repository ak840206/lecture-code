{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37f515-6691-447d-a148-90afd844e49d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Missing Data: In Python\n",
    "\n",
    "There are many notions of 'missing data', and what data is considered missing vs. inaccurate vs. suitable depends heavily on the specific nature of the data and the _goals_ of analyzing that data.\n",
    "\n",
    "But there is a _specific type_ of missing data that we can talk about concretely: Missing data in our programs.\n",
    "\n",
    "## Python and Pandas and Numpy\n",
    "\n",
    "### Introduction and Warning\n",
    "\n",
    "Our tools in this class (Python and libraries) have their own notion of 'missing data'. We can talk about what that is and how to manipulate it, but it's worth repeating: This doesn't tell you _anything_ about what you _should_ do about missing data. Each dataset and analysis will present different problem and what is reasonable to do with the missing data in one analysis may not be reasonable in another!\n",
    "\n",
    "### Python values and Missing Data\n",
    "\n",
    "#### Numpy\n",
    "\n",
    "Let's start with `numpy`.\n",
    "\n",
    "`numpy` has the ability to represent something that is 'not a number', written as `NaN` or `nan`. Consider the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ffd0c-0b93-44e6-92c9-d3cffaf8bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nan(n):\n",
    "    return n == np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ea1fb-70ac-4313-b9a4-619111f47660",
   "metadata": {},
   "source": [
    "It would be reasonable to believe that this function could help you determine whether some field in your dataset is `NaN` or `nan`. Try to predict the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a6ca7-d1c9-40ae-84ae-1799ee4e4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.NaN == np.NaN)\n",
    "print(np.NaN == np.nan)\n",
    "print(np.nan == np.NaN)\n",
    "print(np.nan == np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21092415-a4e0-4f31-90e3-ff022b58d8b5",
   "metadata": {},
   "source": [
    "Because of this, it's safer to use `np.isnan()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feaf66-5f87-4067-b2ab-3d84ec2b1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(np.nan))\n",
    "print(np.isnan(np.NaN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f98e0-b8ea-41c2-beb8-1e531f15d63e",
   "metadata": {
    "tags": []
   },
   "source": [
    "The 'benefit' of `NaN` is that it can be respresented efficiently as a floating point number. The downside of `NaN` is twofold:\n",
    "\n",
    "* there are many `NaN`s, so you cannot reliably check for equality and must therefore use something like `np.isnan`.\n",
    "* we lose out on the distinction between 'missing' and 'went wrong'. `NaN` also represents values where a computation resulted in a calculational error, which isn't the same as 'missing'!\n",
    "\n",
    "#### Python\n",
    "\n",
    "Python values can be `None`. While it can be dangerous to use `None` in your Python code (same issue as Null pointers in Java), the reality is that they do come up, so we'll need to be able to deal with them.\n",
    "\n",
    "#### Pandas\n",
    "\n",
    "Pandas also has some functionality for representing missing values. In particular there are two main Pandas values:\n",
    "\n",
    "* `pd.NA`\n",
    "* `pd.NaT`\n",
    "\n",
    "To see Pandas explanation of why we want `pd.NA` and `pd.NaT` in addition to `NaN`, see the Pandas documentation page on missing values: [https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html). In short, sometimes we want to reason about missing values for a type that cannot be as efficiently represented as a numpy value.\n",
    "\n",
    "* `pd.NA` just means \"not available\"\n",
    "* `pd.NaT` means \"not a time\", which is used when dealing with datetime values. Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a33527-243b-4da2-bbb6-a72ed23a0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = pd.NA\n",
    "print(na == pd.NA) \n",
    "print(na == na)\n",
    "print(pd.NaT == pd.NaT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09628ac-c1c6-4447-8f23-fb65c63904f5",
   "metadata": {},
   "source": [
    "### Manipulating Missing Values\n",
    "\n",
    "Sometimes you want to do something with missing values. Pandas does provide a good amount of functionality for doing so, but it raises an important question: _What does Pandas consider a missing value?_\n",
    "\n",
    "Luckily, we can write some code that will help us answer this question. Study the following dataframe and how it was constructed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = [[\"Numpy NaN\", np.NaN]\n",
    "      ,[\"Numpy NaN 2\", np.nan]\n",
    "      ,[\"Pandas 'Not Available'\", pd.NA]\n",
    "      ,[\"Pandas 'Not a Time'\", pd.NaT]\n",
    "      ,[\"Python None\", None]\n",
    "      ,[\"A String that just says 'NaN'\", \"NaN\"]]\n",
    "\n",
    "df = pd.DataFrame(dat)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c838fc-1730-49b5-868c-d38e433318d7",
   "metadata": {},
   "source": [
    "This dataframe contains all of the 'types' of missing data that we considered above, as well as a string that containts \"NaN\". It's important to test this string because sometimes when you parse data or scrape data from the internet, you get a string that containts \"NaN\" or \"NA\", etc.\n",
    "\n",
    "Pandas provides a bunch of functionality for dealing with missing data (see the link to the documentation above), one such function is `dropna()`, which will remove _all_ rows that contain missing data. This is _almost never_ appropriate, but here we're trying to determine what Pandas considers missing data, so it'll do the trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e532086-3693-40c2-b3ab-1edd5b7e839f",
   "metadata": {},
   "source": [
    "As you can see, all of the 'types' of missing data we showed above are considered \"missing\" by Pandas _except_ the string that containted `\"NaN\"`. The reason for this is simple: it's a string with a value in it, and as such it is not the same as a missing string! A string with `\"NaN\"` in it is just as much a string as a string with `\"North\"` in it, and therefore not 'missing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fe8a9-4944-4ddc-a6d9-433d3f020d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
